{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "ktg1adf"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/flightsPrepare')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "clean flights data, write to Parquet files",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ktg1CSV",
								"type": "DatasetReference"
							},
							"name": "flightsCSV"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "flightsParquet",
								"type": "DatasetReference"
							},
							"name": "writeFlights5M"
						},
						{
							"dataset": {
								"referenceName": "flightsParquet",
								"type": "DatasetReference"
							},
							"name": "write500K"
						},
						{
							"dataset": {
								"referenceName": "flightsParquet",
								"type": "DatasetReference"
							},
							"name": "write50K"
						},
						{
							"dataset": {
								"referenceName": "flightsParquet",
								"type": "DatasetReference"
							},
							"name": "write5K"
						}
					],
					"transformations": [
						{
							"name": "isLate"
						},
						{
							"name": "Clone",
							"description": "Autogenerated by data preview actions"
						},
						{
							"name": "flag500K"
						},
						{
							"name": "flights500K"
						},
						{
							"name": "cleanFlag"
						},
						{
							"name": "departDate"
						},
						{
							"name": "thinColumns"
						},
						{
							"name": "departTime"
						},
						{
							"name": "arrivalTime"
						},
						{
							"name": "cleanColumns"
						},
						{
							"name": "flag5K"
						},
						{
							"name": "flag50K"
						},
						{
							"name": "flights50K"
						},
						{
							"name": "flights5K"
						},
						{
							"name": "setDataTypes"
						}
					],
					"script": "source(output(\n\t\tYEAR as short,\n\t\tMONTH as short,\n\t\tDAY as short,\n\t\tDAY_OF_WEEK as short,\n\t\tAIRLINE as string,\n\t\tFLIGHT_NUMBER as short,\n\t\tTAIL_NUMBER as string,\n\t\tORIGIN_AIRPORT as string,\n\t\tDESTINATION_AIRPORT as string,\n\t\tSCHEDULED_DEPARTURE as string,\n\t\tDEPARTURE_TIME as short,\n\t\tDEPARTURE_DELAY as short,\n\t\tTAXI_OUT as short,\n\t\tWHEELS_OFF as short,\n\t\tSCHEDULED_TIME as short,\n\t\tELAPSED_TIME as short,\n\t\tAIR_TIME as short,\n\t\tDISTANCE as short,\n\t\tWHEELS_ON as short,\n\t\tTAXI_IN as short,\n\t\tSCHEDULED_ARRIVAL as string,\n\t\tARRIVAL_TIME as short,\n\t\tARRIVAL_DELAY as short,\n\t\tDIVERTED as boolean,\n\t\tCANCELLED as boolean,\n\t\tCANCELLATION_REASON as string,\n\t\tAIR_SYSTEM_DELAY as short,\n\t\tSECURITY_DELAY as boolean,\n\t\tAIRLINE_DELAY as short,\n\t\tLATE_AIRCRAFT_DELAY as short,\n\t\tWEATHER_DELAY as short,\n\t\tid as integer\n\t),\n\tallowSchemaDrift: false,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\twildcardPaths:['flights/flightsFull.csv'],\n\tpartitionBy('hash', 32,\n\t\tFLIGHT_NUMBER,\n\t\tTAIL_NUMBER\n\t)) ~> flightsCSV\nflightsCSV derive(late_flight = (ARRIVAL_DELAY>30) || CANCELLED || DIVERTED) ~> isLate\nsetDataTypes select(mapColumn(\n\t\tDAY_OF_WEEK,\n\t\tAIRLINE,\n\t\tFLIGHT_NUMBER,\n\t\tTAIL_NUMBER,\n\t\tORIGIN_AIRPORT,\n\t\tDESTINATION_AIRPORT,\n\t\tDISTANCE,\n\t\tlate_flight,\n\t\tdepart_time,\n\t\tarrival_time\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> Clone\nClone derive({500K} = mod(\r\n    crc32(DAY_OF_WEEK, FLIGHT_NUMBER, DISTANCE,\r\n    depart_time,arrival_time),\r\n    10) == 7) ~> flag500K\nflag500K filter({500K}) ~> flights500K\nthinColumns derive(cleanFlag = false()) ~> cleanFlag\ncleanFlag derive(depart_date = toDate(toString(YEAR)+'-'+toString(MONTH)+'-'+toString(DAY)+ ' ')) ~> departDate\nisLate select(mapColumn(\n\t\tYEAR,\n\t\tMONTH,\n\t\tDAY,\n\t\tDAY_OF_WEEK,\n\t\tAIRLINE,\n\t\tFLIGHT_NUMBER,\n\t\tTAIL_NUMBER,\n\t\tORIGIN_AIRPORT,\n\t\tDESTINATION_AIRPORT,\n\t\tSCHEDULED_DEPARTURE,\n\t\tDEPARTURE_TIME,\n\t\tSCHEDULED_TIME,\n\t\tDISTANCE,\n\t\tSCHEDULED_ARRIVAL,\n\t\tlate_flight\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> thinColumns\ndepartDate derive(depart_time = toTimestamp(toString(depart_date) + ' ' + \r\n    left( SCHEDULED_DEPARTURE,2) + ':' + \r\n    right(SCHEDULED_DEPARTURE,2), \r\n'yyyy-MM-dd HH:mm')) ~> departTime\ndepartTime derive(arrival_time = depart_time + minutes(toInteger(SCHEDULED_TIME))) ~> arrivalTime\narrivalTime select(mapColumn(\n\t\tDAY_OF_WEEK,\n\t\tAIRLINE,\n\t\tFLIGHT_NUMBER,\n\t\tTAIL_NUMBER,\n\t\tORIGIN_AIRPORT,\n\t\tDESTINATION_AIRPORT,\n\t\tDISTANCE,\n\t\tlate_flight,\n\t\tdepart_time,\n\t\tarrival_time\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> cleanColumns\nClone derive({5K} = mod(\r\n    crc32(DAY_OF_WEEK, FLIGHT_NUMBER, DISTANCE,\r\n    depart_time,arrival_time),\r\n    1000) == 7) ~> flag5K\nClone derive({50K} = mod(\r\n    crc32(DAY_OF_WEEK, FLIGHT_NUMBER, DISTANCE,\r\n    depart_time,arrival_time),\r\n    100) == 7) ~> flag50K\nflag50K filter({50K}) ~> flights50K\nflag5K filter({5K}) ~> flights5K\ncleanColumns derive(DAY_OF_WEEK = toInteger(DAY_OF_WEEK),\n\t\tFLIGHT_NUMBER = toInteger(FLIGHT_NUMBER),\n\t\tDISTANCE = toInteger(DISTANCE)) ~> setDataTypes\nClone sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tfilePattern:'5M/part[n].parquet',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> writeFlights5M\nflights500K sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tfilePattern:'500K/part[n].parquet',\n\tmapColumn(\n\t\tDAY_OF_WEEK,\n\t\tAIRLINE,\n\t\tFLIGHT_NUMBER,\n\t\tTAIL_NUMBER,\n\t\tORIGIN_AIRPORT,\n\t\tDESTINATION_AIRPORT,\n\t\tDISTANCE,\n\t\tlate_flight,\n\t\tdepart_time,\n\t\tarrival_time\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> write500K\nflights50K sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tfilePattern:'50K/part[n].parquet',\n\tmapColumn(\n\t\tDAY_OF_WEEK,\n\t\tAIRLINE,\n\t\tFLIGHT_NUMBER,\n\t\tTAIL_NUMBER,\n\t\tORIGIN_AIRPORT,\n\t\tDESTINATION_AIRPORT,\n\t\tDISTANCE,\n\t\tlate_flight,\n\t\tdepart_time,\n\t\tarrival_time\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> write50K\nflights5K sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tfilePattern:'5K/part[n].parquet',\n\tmapColumn(\n\t\tDAY_OF_WEEK,\n\t\tAIRLINE,\n\t\tFLIGHT_NUMBER,\n\t\tTAIL_NUMBER,\n\t\tORIGIN_AIRPORT,\n\t\tDESTINATION_AIRPORT,\n\t\tDISTANCE,\n\t\tlate_flight,\n\t\tdepart_time,\n\t\tarrival_time\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> write5K"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/inpsectFiles')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Look at Parquet contents",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "flightsParquet",
								"type": "DatasetReference"
							},
							"name": "source"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ktg1CSV",
								"type": "DatasetReference"
							},
							"name": "sinkhole"
						}
					],
					"transformations": [],
					"script": "source(output(\n\t\tDAY_OF_WEEK as short,\n\t\tAIRLINE as string,\n\t\tFLIGHT_NUMBER as short,\n\t\tTAIL_NUMBER as string,\n\t\tORIGIN_AIRPORT as string,\n\t\tDESTINATION_AIRPORT as string,\n\t\tDISTANCE as short,\n\t\tlate_flight as boolean,\n\t\tcleanFlag as boolean,\n\t\tdepart_time as timestamp,\n\t\tarrival_time as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tformat: 'parquet',\n\twildcardPaths:['parquet/500K']) ~> source\nsource sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['temp/junk.csv'],\n\tpartitionBy('hash', 1),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> sinkhole"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/parquet2AVRO')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "flightsParquet",
								"type": "DatasetReference"
							},
							"name": "parquet5K"
						},
						{
							"dataset": {
								"referenceName": "flightsParquet",
								"type": "DatasetReference"
							},
							"name": "parquet50K"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "flightsAVRO",
								"type": "DatasetReference"
							},
							"name": "writeAVRO5K"
						},
						{
							"dataset": {
								"referenceName": "flightsAVRO",
								"type": "DatasetReference"
							},
							"name": "writeAVRO50K"
						}
					],
					"transformations": [],
					"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: true,\n\tignoreNoFilesFound: false,\n\tformat: 'parquet',\n\twildcardPaths:['parquet/5K/*']) ~> parquet5K\nsource(allowSchemaDrift: true,\n\tvalidateSchema: true,\n\tignoreNoFilesFound: false,\n\tformat: 'parquet',\n\twildcardPaths:['parquet/50K/*']) ~> parquet50K\nparquet5K sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['flights5K.avro'],\n\tpartitionBy('hash', 1),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> writeAVRO5K\nparquet50K sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['flights50K.avro'],\n\tpartitionBy('hash', 1),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> writeAVRO50K"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/parquet2CSV')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "flightsParquet",
								"type": "DatasetReference"
							},
							"name": "parquet5K"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "flightsCSV",
								"type": "DatasetReference"
							},
							"name": "writeCSV"
						}
					],
					"transformations": [],
					"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: true,\n\tignoreNoFilesFound: false,\n\tformat: 'parquet',\n\twildcardPaths:['parquet/5K/*']) ~> parquet5K\nparquet5K sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['flights5K.csv'],\n\ttruncate: true,\n\tpartitionBy('hash', 1),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> writeCSV"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/flightsPreparePipe')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "flightsPrepare",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "CleanOutputFolder",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "flightsPrepare",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"flightsCSV": {},
									"writeFlights5M": {},
									"write500K": {},
									"write50K": {},
									"write5K": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							}
						}
					},
					{
						"name": "CleanOutputFolder",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "flightsParquet",
								"type": "DatasetReference",
								"parameters": {}
							},
							"logStorageSettings": {
								"linkedServiceName": {
									"referenceName": "ktg1blob",
									"type": "LinkedServiceReference"
								},
								"path": "logs"
							},
							"enableLogging": true,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"wildcardFileName": "*"
							}
						}
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/flightsPrepare')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/translatorAVRO')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "parquet2AVRO",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "CleanOutputFolder",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "parquet2AVRO",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"parquet5K": {},
									"parquet50K": {},
									"writeAVRO5K": {},
									"writeAVRO50K": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							}
						}
					},
					{
						"name": "CleanOutputFolder",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "flightsAVRO",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"wildcardFileName": "*"
							}
						}
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/parquet2AVRO')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/translatorCSV')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "parquet2CSV",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "parquet2CSV",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"parquet5K": {},
									"writeCSV": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							}
						}
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/parquet2CSV')]"
			]
		}
	]
}